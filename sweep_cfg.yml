name: sweep_test
program: experiments/training.py
method: random
metric:
  name: val_loss
  goal: minimize
parameters:
  sweep_parameters:
    # Alright, so here's the deal: during a W&B sweep, wandb.config contains the
    # parameters set for the current sweep run. They can be nested, e.g.
    # wandb.config['training_settings']['initial_lr']
    # HOWEVER, if the config in the training run contains other parameters in the
    # first nesting level (e.g. cfg['training_settings']['weight_decay']) that are
    # not decided by the sweep, they CANT be added into wandb.config['training_settings']
    # because W&B locks the 'training_settings' key.
    # As a result, all entries in the "training_settings" key would be not be saved...
    # A workaroung is to define a key specifically for sweeps "sweep_parameters", and then
    # retrieve the sweep-dediced params via wandb.config['sweep_parameters']. 
    parameters:
      training_settings:
        parameters:
          initial_lr:
            distribution: uniform
            min: 0.0001
            max: 0.1

command:
  - python
  - ${program}
  - "--sweep"
