experiment:
  name: test_cbam
  # Number of past time steps given as input
  past_steps: 4
  # Number of time steps to predict at once
  future_steps: 4
tasks:
  # Parameters specific to each task
  # Output distribution:
  # - "deterministic" (MSE loss)
  # - "normal"
  # - "qc" (quantiles composite)
  # vmax:
    # output_variables: ['INTENSITY']
    # distribution: deterministic
  # mslp:
    # output_variables: ['MSLP']
    # distribution: deterministic
  # r34_avg:
    # output_variables: ['R35_4qAVG']
    # distribution: deterministic
  # location:
    # output_variables: ['LAT', 'LON']
    # distribution: deterministic
training_settings:
  epochs: 100
  batch_size: 128
  # Trainer precision, usually "bf16-mixed" or "32-true"
  precision: 32-true
  # Learning-related params
  initial_lr: 0.01
  # Weight decay
  weight_decay: 0
model_hyperparameters:
  # Number of convolutional blocks (Each block has 2 Conv layers)
  encoder_depth: 4
  # Number of channels in the first hidden layer
  encoder_channels: 16
  # Number of channels in the output of the Common Linear Module
  # (also the channels in the decoder input)
  clm_output_channels: 4

